{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_data = load_dataset(\"sahil2801/CodeAlpaca-20k\")[\"train\"]\n",
    "fin_data = load_dataset(\"FinGPT/fingpt-sentiment-train\")[\"train\"]\n",
    "med_data = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")[\"train\"]\n",
    "general_data = load_dataset(\"tatsu-lab/alpaca\")[\"train\"]\n",
    "math_data = load_dataset(\"TIGER-Lab/MathInstruct\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpaca_format(example):\n",
    "    if example['input'] == \"\":\n",
    "        example[\"instruction\"] = example[\"instruction\"]\n",
    "    else:\n",
    "        example[\"instruction\"] = example[\"instruction\"] + \" \" + example['input']\n",
    "    example[\"response\"] = example['output']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sft_dataset(dataset_name, dataset, dataset_sample)->datasets.Dataset:\n",
    "    if dataset_name in [\"lucasmccabe-lmi/CodeAlpaca-20k\", \"yahma/alpaca-cleaned\", \"FinGPT/fingpt-sentiment-train\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"WizardLM/WizardLM_evol_instruct_70k\"]:\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif dataset_name in [\"tatsu-lab/alpaca\", \"vicgalle/alpaca-gpt4\", \"gbharti/finance-alpaca\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output', 'text'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"TIGER-Lab/MathInstruct\"]:\n",
    "        df = pd.DataFrame(dataset)\n",
    "        df = df.drop_duplicates(subset=['instruction'])\n",
    "        dataset = datasets.Dataset.from_pandas(df)\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "    elif dataset_name in [\"lighteval/MATH\"]:\n",
    "        dataset = dataset.rename_column(\"solution\", \"response\")\n",
    "        dataset = dataset.rename_column(\"problem\", \"instruction\")\n",
    "        dataset = dataset.remove_columns(['level', 'type'])\n",
    "    elif dataset_name in ['gsm8k']:\n",
    "        dataset = dataset.rename_column(\"question\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"answer\", \"response\")\n",
    "    elif dataset_name in ['medalpaca/medical_meadow_medical_flashcards']:       # TODO: 'lavita/ChatDoctor-HealthCareMagic-100k'. not sure whether to discard the instruction.\n",
    "        dataset = dataset.remove_columns(['instruction'])\n",
    "        dataset = dataset.rename_column(\"input\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif \"math\" in dataset_name:\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Dataset {dataset_name} is not supported.\")\n",
    "    dataset = dataset.shuffle(seed=2023)\n",
    "    if dataset_sample:\n",
    "        num_sample = min(len(dataset), dataset_sample)\n",
    "        dataset = dataset.select(range(num_sample))\n",
    "    print(f\">> ===== After processing, Dataset {dataset_name} has {len(dataset)} examples. =====\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> ===== After processing, Dataset lucasmccabe-lmi/CodeAlpaca-20k has 20022 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset FinGPT/fingpt-sentiment-train has 76772 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset medalpaca/medical_meadow_medical_flashcards has 33955 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset tatsu-lab/alpaca has 52002 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset TIGER-Lab/MathInstruct has 224567 examples. =====\n",
      "['response', 'instruction', '__index_level_0__']\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "for name, dataset in zip([\"lucasmccabe-lmi/CodeAlpaca-20k\",\"FinGPT/fingpt-sentiment-train\",\"medalpaca/medical_meadow_medical_flashcards\",\"tatsu-lab/alpaca\",\"TIGER-Lab/MathInstruct\"],[code_data,fin_data,med_data,general_data,math_data]):\n",
    "    tmp:datasets.Dataset = process_sft_dataset(name,dataset,None)\n",
    "    print(tmp.column_names)\n",
    "    processed_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concated = concatenate_datasets(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造base数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(10)\n",
    "sampled_indices = random.sample(range(len(processed_data[0])), 1000)\n",
    "sampled_data = processed_data[0].select(sampled_indices)\n",
    "sampled_set = set(sampled_indices)\n",
    "base_set = set(range(len(data_concated)))\n",
    "\n",
    "# 计算差集，即在 idx_set 中但不在 sampled_set 中的元素\n",
    "remaining_idx = list(base_set - sampled_set)\n",
    "print(len(remaining_idx))\n",
    "data_concated = data_concated.select(remaining_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将base数据集随机拆成十份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = sampled_data.shuffle(seed=42)  \n",
    "local_datasets = []\n",
    "for i in range(10):\n",
    "    local_datasets.append(sampled_data.shard(10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(local_datasets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将公共数据集也随机拆成10份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concated = data_concated.shuffle(seed=42)\n",
    "public_datasets = []\n",
    "for i in range(10):\n",
    "    public_datasets.append(data_concated.shard(10,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造随机采样数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "client_random_datasets = []\n",
    "dataset: Dataset\n",
    "for dataset in public_datasets:\n",
    "    idxs = random.sample(range(len(dataset)), 5000)\n",
    "    client_random_datasets.append(dataset.select(idxs))\n",
    "print(len(client_random_datasets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041000b3833d493494202780bceba54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1344860e0bf944a6a14728d8a9157a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461b72a806ee48cb92510d3888756dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a09c7b757a41e4ab710b7da08ceb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9e7a422678402caa8afa1d1ec9a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1ecdc94dd94af3a0646a9d01bb642c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bbf6bc1a5c48aba5ef8301b97c121d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d138f5e9890041789f0331598b14d96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545f0dddacd441a0afea2a7da76f8ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c497c7f1f02f4bc1a2a4bdf2ce026b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, dataset in enumerate(client_random_datasets):\n",
    "    dataset.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/random_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对每一个客户端的数据集进行检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17762937b7554e14a7cd4f62499db3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8ca1aa565e4daca7f048c866620232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96978dea67843f8977bb58b2e385691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dc9f694373431e9c36e11805ab7193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7324e51c9f341a683c34bffc770b7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2776586cd7bc42f0a1a17085547ea541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------using 8*GPUs----------\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "model = FlagModel('BAAI/bge-large-en-v1.5', \n",
    "                  query_instruction_for_retrieval=\"\",\n",
    "                  use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_pos_datasets, client_neg_datasets = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:18<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "KMeans(n_clusters=10, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "for i, sampled_data in enumerate(local_datasets):\n",
    "    print(i)\n",
    "    sampled_embeddings = model.encode(sampled_data[\"instruction\"])\n",
    "    from sklearn.cluster import KMeans\n",
    "    # 假设 embeddings 是你的嵌入数据\n",
    "    k = 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(sampled_embeddings)\n",
    "    print(kmeans)\n",
    "    from tqdm import tqdm\n",
    "    concated_embeddings = model.encode(public_datasets[i][\"instruction\"])\n",
    "    import torch\n",
    "    clusters = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32)\n",
    "    concated_embeddings = torch.tensor(concated_embeddings, dtype=torch.float32)\n",
    "    import torch\n",
    "    import heapq\n",
    "    similarity_scores = clusters @ concated_embeddings.T\n",
    "    top_idxs = []\n",
    "    bot_idxs = []\n",
    "    for i in range(similarity_scores.shape[0]):\n",
    "        tmp = similarity_scores[i]\n",
    "        top_idxs.append(heapq.nlargest(500, range(len(tmp)), key=tmp.__getitem__))\n",
    "        bot_idxs.append(heapq.nsmallest(500, range(len(tmp)), key=tmp.__getitem__))\n",
    "    pos_datasets: Dataset = []\n",
    "    neg_datasets: Dataset = []\n",
    "    for i in range(len(top_idxs)):\n",
    "        instruction_length = len(public_datasets[i][\"instruction\"])\n",
    "        filtered_top_idxs = list(filter(lambda idx: idx < instruction_length, top_idxs[i]))\n",
    "        filtered_bot_idxs = list(filter(lambda idx: idx < instruction_length, bot_idxs[i]))\n",
    "        pos_datasets.append(public_datasets[i].select(filtered_top_idxs))\n",
    "        neg_datasets.append(public_datasets[i].select(filtered_bot_idxs))\n",
    "    pos_datasets = concatenate_datasets([concatenate_datasets(pos_datasets), sampled_data])\n",
    "    neg_datasets = concatenate_datasets([concatenate_datasets(neg_datasets), sampled_data])\n",
    "    pos_datasets = pos_datasets.shuffle(seed=42)\n",
    "    neg_datasets = neg_datasets.shuffle(seed=42)\n",
    "    client_pos_datasets.append(pos_datasets)\n",
    "    client_neg_datasets.append(neg_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3397cbb5c2434585ff4c201edbe6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5436e069c8f848d999f3fcabf68c15b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830db516a8b8480590989e81d1229ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f67af0c1e745fdbd8c961cea0dd4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdd3950467a487d92016371f7b00648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7088edcec9483fbdc0426fc038faca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35ecd4d03ae4222978da1fa6f19266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53294f19dd946cc948c528e89206c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613f3c3f00f74a03a3fda50aa1450237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0a5c27cb684647a56972155205cdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c3c9ecae7a45669c682d871cf359e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5581ffde4ad4bd58d32f71edd30f81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da37db890316465e8404038f78303796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04509cb2770745e6a8a9845f012848ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1a9ed1b9ee432992f82ed38b3d3b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb904250e85471fbebf542b55f86c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d56e65b50164b728ad7b13ba93c2848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d98e0d2df18492ca1478a474abaa189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e72a93232f41c0bb9e64dcc688893c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f8587fa6ba49da991cffc5e5bde5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (pos_data, neg_data) in enumerate(zip(client_pos_datasets, client_neg_datasets)):\n",
    "    pos_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/pos_{i}.parquet\")\n",
    "    neg_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/neg_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mpos_data\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pos_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(pos_data[\"instruction\"]))\n",
    "print(len(pos_data[\"response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
