{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_data = load_dataset(\"sahil2801/CodeAlpaca-20k\")[\"train\"]\n",
    "fin_data = load_dataset(\"FinGPT/fingpt-sentiment-train\")[\"train\"]\n",
    "med_data = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")[\"train\"]\n",
    "general_data = load_dataset(\"tatsu-lab/alpaca\")[\"train\"]\n",
    "math_data = load_dataset(\"TIGER-Lab/MathInstruct\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpaca_format(example):\n",
    "    if example['input'] == \"\":\n",
    "        example[\"instruction\"] = example[\"instruction\"]\n",
    "    else:\n",
    "        example[\"instruction\"] = example[\"instruction\"] + \" \" + example['input']\n",
    "    example[\"response\"] = example['output']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sft_dataset(dataset_name, dataset, dataset_sample=None)->datasets.Dataset:\n",
    "    if dataset_name in [\"lucasmccabe-lmi/CodeAlpaca-20k\", \"yahma/alpaca-cleaned\", \"FinGPT/fingpt-sentiment-train\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"WizardLM/WizardLM_evol_instruct_70k\"]:\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif dataset_name in [\"tatsu-lab/alpaca\", \"vicgalle/alpaca-gpt4\", \"gbharti/finance-alpaca\"]:\n",
    "        dataset = dataset.map(alpaca_format, remove_columns=['input', 'output', 'text'], desc=f\"Preprocessing {dataset_name} for unified format.\")\n",
    "    elif dataset_name in [\"TIGER-Lab/MathInstruct\"]:\n",
    "        df = pd.DataFrame(dataset)\n",
    "        df = df.drop_duplicates(subset=['instruction'])\n",
    "        dataset = datasets.Dataset.from_pandas(df)\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "    elif dataset_name in [\"lighteval/MATH\"]:\n",
    "        dataset = dataset.rename_column(\"solution\", \"response\")\n",
    "        dataset = dataset.rename_column(\"problem\", \"instruction\")\n",
    "        dataset = dataset.remove_columns(['level', 'type'])\n",
    "    elif dataset_name in ['gsm8k']:\n",
    "        dataset = dataset.rename_column(\"question\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"answer\", \"response\")\n",
    "    elif dataset_name in ['medalpaca/medical_meadow_medical_flashcards']:       # TODO: 'lavita/ChatDoctor-HealthCareMagic-100k'. not sure whether to discard the instruction.\n",
    "        dataset = dataset.remove_columns(['instruction'])\n",
    "        dataset = dataset.rename_column(\"input\", \"instruction\")\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    elif \"math\" in dataset_name:\n",
    "        dataset = dataset.remove_columns(['source'])\n",
    "        dataset = dataset.rename_column(\"output\", \"response\")\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Dataset {dataset_name} is not supported.\")\n",
    "    dataset = dataset.shuffle(seed=2023)\n",
    "    if dataset_sample:\n",
    "        num_sample = min(len(dataset), dataset_sample)\n",
    "        dataset = dataset.select(range(num_sample))\n",
    "    print(f\">> ===== After processing, Dataset {dataset_name} has {len(dataset)} examples. =====\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> ===== After processing, Dataset lucasmccabe-lmi/CodeAlpaca-20k has 20022 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset FinGPT/fingpt-sentiment-train has 76772 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset medalpaca/medical_meadow_medical_flashcards has 33955 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset tatsu-lab/alpaca has 52002 examples. =====\n",
      "['instruction', 'response']\n",
      ">> ===== After processing, Dataset TIGER-Lab/MathInstruct has 224567 examples. =====\n",
      "['response', 'instruction', '__index_level_0__']\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "for name, dataset in zip([\"lucasmccabe-lmi/CodeAlpaca-20k\",\"FinGPT/fingpt-sentiment-train\",\"medalpaca/medical_meadow_medical_flashcards\",\"tatsu-lab/alpaca\",\"TIGER-Lab/MathInstruct\"],[code_data,fin_data,med_data,general_data,math_data]):\n",
    "    tmp:datasets.Dataset = process_sft_dataset(name,dataset)\n",
    "    print(tmp.column_names)\n",
    "    processed_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concated = concatenate_datasets(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造base数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(10)\n",
    "sampled_indices = random.sample(range(len(processed_data[0])), 1000)\n",
    "sampled_data = processed_data[0].select(sampled_indices)\n",
    "sampled_set = set(sampled_indices)\n",
    "base_set = set(range(len(data_concated)))\n",
    "# 计算差集，即在 idx_set 中但不在 sampled_set 中的元素\n",
    "remaining_idx = list(base_set - sampled_set)\n",
    "print(len(remaining_idx))\n",
    "data_concated = data_concated.select(remaining_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将base数据集随机拆成十份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = sampled_data.shuffle(seed=42)  \n",
    "local_datasets = []\n",
    "for i in range(10):\n",
    "    local_datasets.append(sampled_data.shard(10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(local_datasets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将公共数据集也随机拆成10份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concated = data_concated.shuffle(seed=42)\n",
    "public_datasets = []\n",
    "for i in range(10):\n",
    "    public_datasets.append(data_concated.shard(10,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造随机采样数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "client_random_datasets = []\n",
    "dataset: Dataset\n",
    "for dataset in public_datasets:\n",
    "    idxs = random.sample(range(len(dataset)), 5000)\n",
    "    client_random_datasets.append(dataset.select(idxs))\n",
    "print(len(client_random_datasets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e2440a1ac74f4e8a6b9d2dda7b454c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f24ddd460e499ab96672b0393d7a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93df7cc6b1c45b2a210b818f7e26dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4fe5e3a87444b29e12e713b93769d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6136bc9b90324e75919a17c4cee7ed1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea1caa31d7c4d6fbb84afa378851c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efa5faca8ca48b99716bcb34b8d378b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e8fe1083d14d13bd8ed01305ee91a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f5256cdb9c4edda585f36be0e16cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9791a16dfd8a4b05b51522ce63bcdbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, dataset in enumerate(client_random_datasets):\n",
    "    dataset = concatenate_datasets([dataset,local_datasets[i]]).shuffle(seed=42)\n",
    "    dataset.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/random_with_base_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对每一个客户端的数据集进行检索，构造 pos 和 neg 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------using 8*GPUs----------\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "model = FlagModel('BAAI/bge-large-en-v1.5', \n",
    "                  query_instruction_for_retrieval=\"\",\n",
    "                  use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heapq.nlargest(500, range(len(numbers)), key=lambda x: numbers[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9a606c5f5146e097f0f6a330a44969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/40532 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "public_datasets[0].save_to_disk(\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.6716), tensor(0.6623), tensor(0.6423), tensor(0.6422), tensor(0.6420), tensor(0.6408), tensor(0.6408), tensor(0.6386), tensor(0.6314), tensor(0.6310)]\n",
      "[tensor(0.2119), tensor(0.2182), tensor(0.2213), tensor(0.2292), tensor(0.2306), tensor(0.2319), tensor(0.2331), tensor(0.2358), tensor(0.2361), tensor(0.2376)]\n",
      "1\n",
      "[tensor(0.7447), tensor(0.7424), tensor(0.7290), tensor(0.7249), tensor(0.7165), tensor(0.7165), tensor(0.7152), tensor(0.7093), tensor(0.7077), tensor(0.7066)]\n",
      "[tensor(0.2246), tensor(0.2262), tensor(0.2264), tensor(0.2271), tensor(0.2273), tensor(0.2331), tensor(0.2431), tensor(0.2449), tensor(0.2478), tensor(0.2494)]\n",
      "2\n",
      "[tensor(0.7038), tensor(0.6996), tensor(0.6914), tensor(0.6863), tensor(0.6837), tensor(0.6805), tensor(0.6783), tensor(0.6780), tensor(0.6776), tensor(0.6733)]\n",
      "[tensor(0.2140), tensor(0.2180), tensor(0.2380), tensor(0.2442), tensor(0.2445), tensor(0.2479), tensor(0.2510), tensor(0.2526), tensor(0.2528), tensor(0.2575)]\n",
      "3\n",
      "[tensor(0.6978), tensor(0.6950), tensor(0.6947), tensor(0.6937), tensor(0.6906), tensor(0.6896), tensor(0.6859), tensor(0.6859), tensor(0.6848), tensor(0.6847)]\n",
      "[tensor(0.2125), tensor(0.2254), tensor(0.2310), tensor(0.2323), tensor(0.2366), tensor(0.2383), tensor(0.2425), tensor(0.2432), tensor(0.2469), tensor(0.2490)]\n",
      "4\n",
      "[tensor(0.6594), tensor(0.6587), tensor(0.6552), tensor(0.6515), tensor(0.6454), tensor(0.6403), tensor(0.6352), tensor(0.6346), tensor(0.6333), tensor(0.6307)]\n",
      "[tensor(0.1944), tensor(0.2346), tensor(0.2386), tensor(0.2428), tensor(0.2461), tensor(0.2470), tensor(0.2472), tensor(0.2482), tensor(0.2484), tensor(0.2495)]\n",
      "5\n",
      "[tensor(0.7583), tensor(0.7495), tensor(0.7398), tensor(0.7390), tensor(0.7352), tensor(0.7342), tensor(0.7280), tensor(0.7278), tensor(0.7270), tensor(0.7246)]\n",
      "[tensor(0.2058), tensor(0.2185), tensor(0.2227), tensor(0.2234), tensor(0.2238), tensor(0.2238), tensor(0.2302), tensor(0.2312), tensor(0.2339), tensor(0.2372)]\n",
      "6\n",
      "[tensor(0.6708), tensor(0.6628), tensor(0.6557), tensor(0.6501), tensor(0.6495), tensor(0.6469), tensor(0.6469), tensor(0.6452), tensor(0.6440), tensor(0.6422)]\n",
      "[tensor(0.2206), tensor(0.2353), tensor(0.2367), tensor(0.2398), tensor(0.2568), tensor(0.2606), tensor(0.2611), tensor(0.2627), tensor(0.2639), tensor(0.2660)]\n",
      "7\n",
      "[tensor(0.6850), tensor(0.6800), tensor(0.6770), tensor(0.6761), tensor(0.6759), tensor(0.6746), tensor(0.6740), tensor(0.6734), tensor(0.6734), tensor(0.6732)]\n",
      "[tensor(0.2143), tensor(0.2299), tensor(0.2381), tensor(0.2436), tensor(0.2449), tensor(0.2465), tensor(0.2533), tensor(0.2543), tensor(0.2553), tensor(0.2556)]\n",
      "8\n",
      "[tensor(0.6620), tensor(0.6602), tensor(0.6497), tensor(0.6477), tensor(0.6467), tensor(0.6449), tensor(0.6426), tensor(0.6416), tensor(0.6407), tensor(0.6387)]\n",
      "[tensor(0.2415), tensor(0.2464), tensor(0.2486), tensor(0.2525), tensor(0.2548), tensor(0.2559), tensor(0.2624), tensor(0.2648), tensor(0.2684), tensor(0.2698)]\n",
      "9\n",
      "[tensor(0.8778), tensor(0.8772), tensor(0.8471), tensor(0.8448), tensor(0.8212), tensor(0.8081), tensor(0.8079), tensor(0.8051), tensor(0.7945), tensor(0.7918)]\n",
      "[tensor(0.2136), tensor(0.2137), tensor(0.2171), tensor(0.2268), tensor(0.2308), tensor(0.2323), tensor(0.2325), tensor(0.2342), tensor(0.2373), tensor(0.2382)]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.7223), tensor(0.7146), tensor(0.7128), tensor(0.7119), tensor(0.7081), tensor(0.7060), tensor(0.7054), tensor(0.7052), tensor(0.7028), tensor(0.7019)]\n",
      "[tensor(0.2167), tensor(0.2241), tensor(0.2268), tensor(0.2274), tensor(0.2289), tensor(0.2377), tensor(0.2378), tensor(0.2395), tensor(0.2396), tensor(0.2422)]\n",
      "1\n",
      "[tensor(0.6424), tensor(0.6419), tensor(0.6397), tensor(0.6366), tensor(0.6331), tensor(0.6315), tensor(0.6309), tensor(0.6303), tensor(0.6297), tensor(0.6289)]\n",
      "[tensor(0.2353), tensor(0.2412), tensor(0.2498), tensor(0.2615), tensor(0.2621), tensor(0.2654), tensor(0.2669), tensor(0.2674), tensor(0.2677), tensor(0.2683)]\n",
      "2\n",
      "[tensor(0.7071), tensor(0.7006), tensor(0.6983), tensor(0.6964), tensor(0.6964), tensor(0.6959), tensor(0.6949), tensor(0.6910), tensor(0.6910), tensor(0.6899)]\n",
      "[tensor(0.2100), tensor(0.2110), tensor(0.2347), tensor(0.2379), tensor(0.2395), tensor(0.2402), tensor(0.2466), tensor(0.2467), tensor(0.2498), tensor(0.2503)]\n",
      "3\n",
      "[tensor(0.6862), tensor(0.6819), tensor(0.6803), tensor(0.6796), tensor(0.6775), tensor(0.6769), tensor(0.6765), tensor(0.6757), tensor(0.6755), tensor(0.6748)]\n",
      "[tensor(0.2128), tensor(0.2383), tensor(0.2433), tensor(0.2434), tensor(0.2443), tensor(0.2458), tensor(0.2460), tensor(0.2463), tensor(0.2464), tensor(0.2507)]\n",
      "4\n",
      "[tensor(0.6230), tensor(0.6221), tensor(0.6198), tensor(0.6112), tensor(0.6096), tensor(0.6095), tensor(0.6080), tensor(0.6068), tensor(0.6059), tensor(0.6049)]\n",
      "[tensor(0.2250), tensor(0.2406), tensor(0.2505), tensor(0.2564), tensor(0.2621), tensor(0.2623), tensor(0.2632), tensor(0.2635), tensor(0.2653), tensor(0.2665)]\n",
      "5\n",
      "[tensor(0.7130), tensor(0.7114), tensor(0.7097), tensor(0.7084), tensor(0.7079), tensor(0.7007), tensor(0.6972), tensor(0.6970), tensor(0.6960), tensor(0.6941)]\n",
      "[tensor(0.2028), tensor(0.2342), tensor(0.2441), tensor(0.2455), tensor(0.2463), tensor(0.2489), tensor(0.2496), tensor(0.2508), tensor(0.2509), tensor(0.2514)]\n",
      "6\n",
      "[tensor(0.6645), tensor(0.6594), tensor(0.6557), tensor(0.6544), tensor(0.6521), tensor(0.6478), tensor(0.6451), tensor(0.6447), tensor(0.6368), tensor(0.6347)]\n",
      "[tensor(0.2282), tensor(0.2351), tensor(0.2579), tensor(0.2586), tensor(0.2606), tensor(0.2610), tensor(0.2619), tensor(0.2621), tensor(0.2622), tensor(0.2635)]\n",
      "7\n",
      "[tensor(0.7359), tensor(0.7202), tensor(0.7180), tensor(0.7178), tensor(0.7170), tensor(0.7169), tensor(0.7157), tensor(0.7101), tensor(0.7083), tensor(0.7069)]\n",
      "[tensor(0.2035), tensor(0.2380), tensor(0.2466), tensor(0.2486), tensor(0.2537), tensor(0.2549), tensor(0.2562), tensor(0.2629), tensor(0.2638), tensor(0.2654)]\n",
      "8\n",
      "[tensor(0.7085), tensor(0.7003), tensor(0.6974), tensor(0.6967), tensor(0.6915), tensor(0.6905), tensor(0.6865), tensor(0.6799), tensor(0.6771), tensor(0.6724)]\n",
      "[tensor(0.2009), tensor(0.2336), tensor(0.2352), tensor(0.2355), tensor(0.2445), tensor(0.2478), tensor(0.2510), tensor(0.2532), tensor(0.2540), tensor(0.2560)]\n",
      "9\n",
      "[tensor(0.6684), tensor(0.6584), tensor(0.6547), tensor(0.6502), tensor(0.6495), tensor(0.6493), tensor(0.6492), tensor(0.6479), tensor(0.6477), tensor(0.6474)]\n",
      "[tensor(0.2345), tensor(0.2355), tensor(0.2396), tensor(0.2422), tensor(0.2459), tensor(0.2465), tensor(0.2468), tensor(0.2495), tensor(0.2499), tensor(0.2503)]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.6415), tensor(0.6379), tensor(0.6374), tensor(0.6371), tensor(0.6367), tensor(0.6343), tensor(0.6332), tensor(0.6322), tensor(0.6321), tensor(0.6316)]\n",
      "[tensor(0.2386), tensor(0.2400), tensor(0.2499), tensor(0.2608), tensor(0.2623), tensor(0.2646), tensor(0.2678), tensor(0.2682), tensor(0.2689), tensor(0.2689)]\n",
      "1\n",
      "[tensor(0.7212), tensor(0.7179), tensor(0.7107), tensor(0.7085), tensor(0.7057), tensor(0.7027), tensor(0.7019), tensor(0.7019), tensor(0.7009), tensor(0.7000)]\n",
      "[tensor(0.2287), tensor(0.2316), tensor(0.2357), tensor(0.2401), tensor(0.2414), tensor(0.2453), tensor(0.2467), tensor(0.2492), tensor(0.2494), tensor(0.2505)]\n",
      "2\n",
      "[tensor(0.6972), tensor(0.6944), tensor(0.6906), tensor(0.6897), tensor(0.6893), tensor(0.6832), tensor(0.6804), tensor(0.6784), tensor(0.6771), tensor(0.6768)]\n",
      "[tensor(0.2381), tensor(0.2411), tensor(0.2414), tensor(0.2416), tensor(0.2424), tensor(0.2470), tensor(0.2480), tensor(0.2494), tensor(0.2498), tensor(0.2519)]\n",
      "3\n",
      "[tensor(0.7328), tensor(0.7302), tensor(0.7265), tensor(0.7216), tensor(0.7201), tensor(0.7180), tensor(0.7157), tensor(0.7149), tensor(0.7128), tensor(0.7126)]\n",
      "[tensor(0.2561), tensor(0.2584), tensor(0.2604), tensor(0.2609), tensor(0.2616), tensor(0.2617), tensor(0.2629), tensor(0.2629), tensor(0.2637), tensor(0.2640)]\n",
      "4\n",
      "[tensor(0.7004), tensor(0.6995), tensor(0.6978), tensor(0.6861), tensor(0.6823), tensor(0.6817), tensor(0.6817), tensor(0.6749), tensor(0.6736), tensor(0.6723)]\n",
      "[tensor(0.2049), tensor(0.2221), tensor(0.2278), tensor(0.2289), tensor(0.2293), tensor(0.2297), tensor(0.2324), tensor(0.2337), tensor(0.2340), tensor(0.2342)]\n",
      "5\n",
      "[tensor(0.6691), tensor(0.6613), tensor(0.6600), tensor(0.6584), tensor(0.6582), tensor(0.6561), tensor(0.6544), tensor(0.6533), tensor(0.6507), tensor(0.6501)]\n",
      "[tensor(0.2499), tensor(0.2603), tensor(0.2607), tensor(0.2663), tensor(0.2671), tensor(0.2682), tensor(0.2695), tensor(0.2701), tensor(0.2706), tensor(0.2710)]\n",
      "6\n",
      "[tensor(0.6847), tensor(0.6828), tensor(0.6748), tensor(0.6737), tensor(0.6713), tensor(0.6696), tensor(0.6664), tensor(0.6662), tensor(0.6590), tensor(0.6573)]\n",
      "[tensor(0.2467), tensor(0.2545), tensor(0.2576), tensor(0.2581), tensor(0.2619), tensor(0.2674), tensor(0.2690), tensor(0.2696), tensor(0.2698), tensor(0.2743)]\n",
      "7\n",
      "[tensor(0.7086), tensor(0.6965), tensor(0.6800), tensor(0.6768), tensor(0.6735), tensor(0.6655), tensor(0.6651), tensor(0.6626), tensor(0.6534), tensor(0.6527)]\n",
      "[tensor(0.2280), tensor(0.2290), tensor(0.2342), tensor(0.2396), tensor(0.2424), tensor(0.2441), tensor(0.2444), tensor(0.2460), tensor(0.2475), tensor(0.2479)]\n",
      "8\n",
      "[tensor(0.6630), tensor(0.6425), tensor(0.6408), tensor(0.6393), tensor(0.6365), tensor(0.6350), tensor(0.6342), tensor(0.6329), tensor(0.6326), tensor(0.6252)]\n",
      "[tensor(0.2473), tensor(0.2494), tensor(0.2612), tensor(0.2635), tensor(0.2657), tensor(0.2673), tensor(0.2691), tensor(0.2712), tensor(0.2714), tensor(0.2728)]\n",
      "9\n",
      "[tensor(0.7229), tensor(0.7137), tensor(0.7068), tensor(0.6956), tensor(0.6919), tensor(0.6873), tensor(0.6843), tensor(0.6816), tensor(0.6803), tensor(0.6803)]\n",
      "[tensor(0.2340), tensor(0.2419), tensor(0.2545), tensor(0.2603), tensor(0.2631), tensor(0.2635), tensor(0.2638), tensor(0.2682), tensor(0.2694), tensor(0.2722)]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.6498), tensor(0.6469), tensor(0.6433), tensor(0.6428), tensor(0.6356), tensor(0.6333), tensor(0.6318), tensor(0.6311), tensor(0.6309), tensor(0.6293)]\n",
      "[tensor(0.2371), tensor(0.2398), tensor(0.2553), tensor(0.2558), tensor(0.2568), tensor(0.2589), tensor(0.2607), tensor(0.2612), tensor(0.2618), tensor(0.2634)]\n",
      "1\n",
      "[tensor(0.7750), tensor(0.7488), tensor(0.7482), tensor(0.7433), tensor(0.7408), tensor(0.7354), tensor(0.7345), tensor(0.7338), tensor(0.7328), tensor(0.7325)]\n",
      "[tensor(0.2125), tensor(0.2388), tensor(0.2430), tensor(0.2455), tensor(0.2463), tensor(0.2470), tensor(0.2490), tensor(0.2531), tensor(0.2537), tensor(0.2537)]\n",
      "2\n",
      "[tensor(0.7405), tensor(0.7394), tensor(0.7392), tensor(0.7383), tensor(0.7377), tensor(0.7367), tensor(0.7349), tensor(0.7285), tensor(0.7283), tensor(0.7255)]\n",
      "[tensor(0.2297), tensor(0.2341), tensor(0.2351), tensor(0.2383), tensor(0.2437), tensor(0.2451), tensor(0.2457), tensor(0.2463), tensor(0.2488), tensor(0.2492)]\n",
      "3\n",
      "[tensor(0.6753), tensor(0.6745), tensor(0.6738), tensor(0.6657), tensor(0.6649), tensor(0.6634), tensor(0.6620), tensor(0.6609), tensor(0.6608), tensor(0.6584)]\n",
      "[tensor(0.2329), tensor(0.2334), tensor(0.2402), tensor(0.2405), tensor(0.2465), tensor(0.2488), tensor(0.2511), tensor(0.2526), tensor(0.2549), tensor(0.2567)]\n",
      "4\n",
      "[tensor(0.6994), tensor(0.6969), tensor(0.6967), tensor(0.6962), tensor(0.6924), tensor(0.6901), tensor(0.6898), tensor(0.6878), tensor(0.6859), tensor(0.6844)]\n",
      "[tensor(0.2218), tensor(0.2232), tensor(0.2419), tensor(0.2462), tensor(0.2499), tensor(0.2499), tensor(0.2507), tensor(0.2512), tensor(0.2522), tensor(0.2536)]\n",
      "5\n",
      "[tensor(0.6374), tensor(0.6374), tensor(0.6345), tensor(0.6322), tensor(0.6253), tensor(0.6246), tensor(0.6244), tensor(0.6234), tensor(0.6232), tensor(0.6229)]\n",
      "[tensor(0.2151), tensor(0.2222), tensor(0.2398), tensor(0.2409), tensor(0.2434), tensor(0.2467), tensor(0.2503), tensor(0.2505), tensor(0.2517), tensor(0.2520)]\n",
      "6\n",
      "[tensor(0.7499), tensor(0.7462), tensor(0.7326), tensor(0.7325), tensor(0.7299), tensor(0.7240), tensor(0.7219), tensor(0.7188), tensor(0.7178), tensor(0.7174)]\n",
      "[tensor(0.2533), tensor(0.2568), tensor(0.2624), tensor(0.2625), tensor(0.2627), tensor(0.2650), tensor(0.2673), tensor(0.2679), tensor(0.2680), tensor(0.2681)]\n",
      "7\n",
      "[tensor(0.6864), tensor(0.6837), tensor(0.6753), tensor(0.6721), tensor(0.6713), tensor(0.6704), tensor(0.6699), tensor(0.6699), tensor(0.6663), tensor(0.6650)]\n",
      "[tensor(0.2484), tensor(0.2500), tensor(0.2522), tensor(0.2546), tensor(0.2556), tensor(0.2597), tensor(0.2607), tensor(0.2609), tensor(0.2619), tensor(0.2643)]\n",
      "8\n",
      "[tensor(0.6948), tensor(0.6876), tensor(0.6848), tensor(0.6834), tensor(0.6778), tensor(0.6725), tensor(0.6719), tensor(0.6692), tensor(0.6684), tensor(0.6657)]\n",
      "[tensor(0.2256), tensor(0.2369), tensor(0.2412), tensor(0.2481), tensor(0.2496), tensor(0.2512), tensor(0.2513), tensor(0.2520), tensor(0.2532), tensor(0.2535)]\n",
      "9\n",
      "[tensor(0.6722), tensor(0.6700), tensor(0.6677), tensor(0.6664), tensor(0.6658), tensor(0.6587), tensor(0.6561), tensor(0.6554), tensor(0.6539), tensor(0.6521)]\n",
      "[tensor(0.2330), tensor(0.2367), tensor(0.2387), tensor(0.2389), tensor(0.2516), tensor(0.2560), tensor(0.2612), tensor(0.2612), tensor(0.2616), tensor(0.2624)]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.7488), tensor(0.6886), tensor(0.6838), tensor(0.6745), tensor(0.6658), tensor(0.6593), tensor(0.6546), tensor(0.6453), tensor(0.6442), tensor(0.6312)]\n",
      "[tensor(0.2257), tensor(0.2265), tensor(0.2343), tensor(0.2361), tensor(0.2366), tensor(0.2373), tensor(0.2446), tensor(0.2447), tensor(0.2449), tensor(0.2463)]\n",
      "1\n",
      "[tensor(0.7057), tensor(0.6943), tensor(0.6931), tensor(0.6928), tensor(0.6902), tensor(0.6864), tensor(0.6862), tensor(0.6843), tensor(0.6817), tensor(0.6771)]\n",
      "[tensor(0.2311), tensor(0.2369), tensor(0.2413), tensor(0.2447), tensor(0.2468), tensor(0.2474), tensor(0.2501), tensor(0.2513), tensor(0.2533), tensor(0.2548)]\n",
      "2\n",
      "[tensor(0.7189), tensor(0.6942), tensor(0.6755), tensor(0.6704), tensor(0.6591), tensor(0.6586), tensor(0.6573), tensor(0.6567), tensor(0.6563), tensor(0.6559)]\n",
      "[tensor(0.2283), tensor(0.2355), tensor(0.2449), tensor(0.2474), tensor(0.2479), tensor(0.2489), tensor(0.2490), tensor(0.2493), tensor(0.2524), tensor(0.2538)]\n",
      "3\n",
      "[tensor(0.6754), tensor(0.6749), tensor(0.6655), tensor(0.6620), tensor(0.6618), tensor(0.6607), tensor(0.6473), tensor(0.6465), tensor(0.6440), tensor(0.6409)]\n",
      "[tensor(0.2356), tensor(0.2486), tensor(0.2542), tensor(0.2548), tensor(0.2562), tensor(0.2588), tensor(0.2609), tensor(0.2637), tensor(0.2646), tensor(0.2653)]\n",
      "4\n",
      "[tensor(0.6973), tensor(0.6924), tensor(0.6864), tensor(0.6841), tensor(0.6802), tensor(0.6786), tensor(0.6755), tensor(0.6744), tensor(0.6725), tensor(0.6719)]\n",
      "[tensor(0.2407), tensor(0.2410), tensor(0.2420), tensor(0.2483), tensor(0.2505), tensor(0.2543), tensor(0.2566), tensor(0.2587), tensor(0.2593), tensor(0.2611)]\n",
      "5\n",
      "[tensor(0.7382), tensor(0.7305), tensor(0.7192), tensor(0.6952), tensor(0.6949), tensor(0.6907), tensor(0.6893), tensor(0.6891), tensor(0.6882), tensor(0.6870)]\n",
      "[tensor(0.2551), tensor(0.2555), tensor(0.2561), tensor(0.2562), tensor(0.2562), tensor(0.2566), tensor(0.2590), tensor(0.2615), tensor(0.2617), tensor(0.2619)]\n",
      "6\n",
      "[tensor(0.7142), tensor(0.7056), tensor(0.7027), tensor(0.7026), tensor(0.7013), tensor(0.6999), tensor(0.6985), tensor(0.6978), tensor(0.6971), tensor(0.6955)]\n",
      "[tensor(0.2256), tensor(0.2366), tensor(0.2382), tensor(0.2436), tensor(0.2443), tensor(0.2504), tensor(0.2536), tensor(0.2538), tensor(0.2566), tensor(0.2574)]\n",
      "7\n",
      "[tensor(0.6816), tensor(0.6694), tensor(0.6611), tensor(0.6482), tensor(0.6419), tensor(0.6410), tensor(0.6389), tensor(0.6381), tensor(0.6355), tensor(0.6350)]\n",
      "[tensor(0.2711), tensor(0.2747), tensor(0.2777), tensor(0.2784), tensor(0.2809), tensor(0.2809), tensor(0.2852), tensor(0.2880), tensor(0.2881), tensor(0.2886)]\n",
      "8\n",
      "[tensor(0.6675), tensor(0.6575), tensor(0.6563), tensor(0.6484), tensor(0.6477), tensor(0.6432), tensor(0.6424), tensor(0.6409), tensor(0.6370), tensor(0.6347)]\n",
      "[tensor(0.2325), tensor(0.2369), tensor(0.2395), tensor(0.2427), tensor(0.2445), tensor(0.2471), tensor(0.2519), tensor(0.2526), tensor(0.2526), tensor(0.2560)]\n",
      "9\n",
      "[tensor(0.6896), tensor(0.6844), tensor(0.6766), tensor(0.6760), tensor(0.6742), tensor(0.6678), tensor(0.6624), tensor(0.6611), tensor(0.6611), tensor(0.6610)]\n",
      "[tensor(0.2187), tensor(0.2340), tensor(0.2432), tensor(0.2439), tensor(0.2475), tensor(0.2490), tensor(0.2492), tensor(0.2508), tensor(0.2518), tensor(0.2522)]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.7475), tensor(0.7092), tensor(0.6954), tensor(0.6916), tensor(0.6916), tensor(0.6809), tensor(0.6793), tensor(0.6790), tensor(0.6734), tensor(0.6669)]\n",
      "[tensor(0.1843), tensor(0.1909), tensor(0.2063), tensor(0.2172), tensor(0.2174), tensor(0.2188), tensor(0.2193), tensor(0.2225), tensor(0.2240), tensor(0.2250)]\n",
      "1\n",
      "[tensor(0.6728), tensor(0.6694), tensor(0.6673), tensor(0.6651), tensor(0.6649), tensor(0.6615), tensor(0.6608), tensor(0.6596), tensor(0.6586), tensor(0.6581)]\n",
      "[tensor(0.2447), tensor(0.2482), tensor(0.2520), tensor(0.2603), tensor(0.2634), tensor(0.2636), tensor(0.2654), tensor(0.2655), tensor(0.2673), tensor(0.2675)]\n",
      "2\n",
      "[tensor(0.6521), tensor(0.6166), tensor(0.6136), tensor(0.6123), tensor(0.6099), tensor(0.6090), tensor(0.6058), tensor(0.6052), tensor(0.6047), tensor(0.6040)]\n",
      "[tensor(0.2042), tensor(0.2060), tensor(0.2133), tensor(0.2209), tensor(0.2214), tensor(0.2226), tensor(0.2228), tensor(0.2253), tensor(0.2286), tensor(0.2292)]\n",
      "3\n",
      "[tensor(0.6882), tensor(0.6812), tensor(0.6797), tensor(0.6773), tensor(0.6772), tensor(0.6769), tensor(0.6765), tensor(0.6762), tensor(0.6759), tensor(0.6752)]\n",
      "[tensor(0.1984), tensor(0.2364), tensor(0.2409), tensor(0.2410), tensor(0.2479), tensor(0.2491), tensor(0.2506), tensor(0.2510), tensor(0.2555), tensor(0.2590)]\n",
      "4\n",
      "[tensor(0.7195), tensor(0.7173), tensor(0.7009), tensor(0.6960), tensor(0.6940), tensor(0.6926), tensor(0.6890), tensor(0.6883), tensor(0.6883), tensor(0.6872)]\n",
      "[tensor(0.1920), tensor(0.2214), tensor(0.2287), tensor(0.2319), tensor(0.2324), tensor(0.2334), tensor(0.2360), tensor(0.2369), tensor(0.2386), tensor(0.2391)]\n",
      "5\n",
      "[tensor(0.7667), tensor(0.7371), tensor(0.7230), tensor(0.7146), tensor(0.7055), tensor(0.7047), tensor(0.7039), tensor(0.7022), tensor(0.6979), tensor(0.6965)]\n",
      "[tensor(0.2034), tensor(0.2204), tensor(0.2224), tensor(0.2316), tensor(0.2326), tensor(0.2431), tensor(0.2446), tensor(0.2449), tensor(0.2459), tensor(0.2471)]\n",
      "6\n",
      "[tensor(0.7016), tensor(0.6923), tensor(0.6913), tensor(0.6906), tensor(0.6904), tensor(0.6862), tensor(0.6838), tensor(0.6820), tensor(0.6814), tensor(0.6806)]\n",
      "[tensor(0.2101), tensor(0.2334), tensor(0.2500), tensor(0.2526), tensor(0.2537), tensor(0.2563), tensor(0.2564), tensor(0.2608), tensor(0.2616), tensor(0.2636)]\n",
      "7\n",
      "[tensor(0.6270), tensor(0.6231), tensor(0.6214), tensor(0.6203), tensor(0.6189), tensor(0.6185), tensor(0.6141), tensor(0.6134), tensor(0.6130), tensor(0.6117)]\n",
      "[tensor(0.2393), tensor(0.2447), tensor(0.2512), tensor(0.2512), tensor(0.2521), tensor(0.2527), tensor(0.2542), tensor(0.2545), tensor(0.2583), tensor(0.2602)]\n",
      "8\n",
      "[tensor(0.7514), tensor(0.7341), tensor(0.7312), tensor(0.7296), tensor(0.7294), tensor(0.7281), tensor(0.7251), tensor(0.7212), tensor(0.7211), tensor(0.7199)]\n",
      "[tensor(0.2320), tensor(0.2406), tensor(0.2416), tensor(0.2425), tensor(0.2548), tensor(0.2565), tensor(0.2568), tensor(0.2583), tensor(0.2601), tensor(0.2604)]\n",
      "9\n",
      "[tensor(0.6921), tensor(0.6770), tensor(0.6763), tensor(0.6743), tensor(0.6738), tensor(0.6712), tensor(0.6707), tensor(0.6698), tensor(0.6686), tensor(0.6659)]\n",
      "[tensor(0.2072), tensor(0.2296), tensor(0.2486), tensor(0.2491), tensor(0.2534), tensor(0.2541), tensor(0.2557), tensor(0.2569), tensor(0.2577), tensor(0.2587)]\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.6587), tensor(0.6551), tensor(0.6536), tensor(0.6526), tensor(0.6475), tensor(0.6463), tensor(0.6456), tensor(0.6453), tensor(0.6414), tensor(0.6393)]\n",
      "[tensor(0.2217), tensor(0.2289), tensor(0.2330), tensor(0.2426), tensor(0.2462), tensor(0.2502), tensor(0.2536), tensor(0.2547), tensor(0.2547), tensor(0.2557)]\n",
      "1\n",
      "[tensor(0.7683), tensor(0.7642), tensor(0.7580), tensor(0.7572), tensor(0.7501), tensor(0.7497), tensor(0.7415), tensor(0.7409), tensor(0.7375), tensor(0.7374)]\n",
      "[tensor(0.2138), tensor(0.2193), tensor(0.2370), tensor(0.2397), tensor(0.2445), tensor(0.2452), tensor(0.2453), tensor(0.2461), tensor(0.2474), tensor(0.2527)]\n",
      "2\n",
      "[tensor(0.7136), tensor(0.7092), tensor(0.7030), tensor(0.7016), tensor(0.7015), tensor(0.6933), tensor(0.6923), tensor(0.6917), tensor(0.6907), tensor(0.6906)]\n",
      "[tensor(0.2017), tensor(0.2250), tensor(0.2374), tensor(0.2381), tensor(0.2418), tensor(0.2449), tensor(0.2509), tensor(0.2516), tensor(0.2548), tensor(0.2554)]\n",
      "3\n",
      "[tensor(0.7086), tensor(0.7078), tensor(0.7010), tensor(0.7010), tensor(0.7007), tensor(0.7002), tensor(0.6990), tensor(0.6988), tensor(0.6954), tensor(0.6898)]\n",
      "[tensor(0.2141), tensor(0.2181), tensor(0.2280), tensor(0.2324), tensor(0.2410), tensor(0.2418), tensor(0.2430), tensor(0.2453), tensor(0.2461), tensor(0.2463)]\n",
      "4\n",
      "[tensor(0.7090), tensor(0.6856), tensor(0.6847), tensor(0.6817), tensor(0.6782), tensor(0.6746), tensor(0.6727), tensor(0.6722), tensor(0.6710), tensor(0.6689)]\n",
      "[tensor(0.2300), tensor(0.2321), tensor(0.2383), tensor(0.2421), tensor(0.2475), tensor(0.2480), tensor(0.2531), tensor(0.2540), tensor(0.2546), tensor(0.2556)]\n",
      "5\n",
      "[tensor(0.6830), tensor(0.6651), tensor(0.6453), tensor(0.6327), tensor(0.6318), tensor(0.6251), tensor(0.6235), tensor(0.6183), tensor(0.6175), tensor(0.6154)]\n",
      "[tensor(0.2186), tensor(0.2310), tensor(0.2310), tensor(0.2421), tensor(0.2456), tensor(0.2473), tensor(0.2478), tensor(0.2490), tensor(0.2509), tensor(0.2512)]\n",
      "6\n",
      "[tensor(0.6676), tensor(0.6606), tensor(0.6507), tensor(0.6499), tensor(0.6454), tensor(0.6410), tensor(0.6403), tensor(0.6399), tensor(0.6378), tensor(0.6378)]\n",
      "[tensor(0.2148), tensor(0.2469), tensor(0.2484), tensor(0.2552), tensor(0.2562), tensor(0.2564), tensor(0.2588), tensor(0.2632), tensor(0.2636), tensor(0.2644)]\n",
      "7\n",
      "[tensor(0.6430), tensor(0.6382), tensor(0.6285), tensor(0.6259), tensor(0.6225), tensor(0.6199), tensor(0.6196), tensor(0.6185), tensor(0.6168), tensor(0.6160)]\n",
      "[tensor(0.2282), tensor(0.2393), tensor(0.2432), tensor(0.2466), tensor(0.2476), tensor(0.2481), tensor(0.2486), tensor(0.2500), tensor(0.2547), tensor(0.2553)]\n",
      "8\n",
      "[tensor(0.6593), tensor(0.6138), tensor(0.6103), tensor(0.6003), tensor(0.5988), tensor(0.5962), tensor(0.5942), tensor(0.5917), tensor(0.5888), tensor(0.5880)]\n",
      "[tensor(0.2144), tensor(0.2225), tensor(0.2261), tensor(0.2287), tensor(0.2295), tensor(0.2297), tensor(0.2353), tensor(0.2394), tensor(0.2420), tensor(0.2420)]\n",
      "9\n",
      "[tensor(0.6990), tensor(0.6857), tensor(0.6854), tensor(0.6831), tensor(0.6721), tensor(0.6716), tensor(0.6626), tensor(0.6622), tensor(0.6601), tensor(0.6590)]\n",
      "[tensor(0.2161), tensor(0.2424), tensor(0.2481), tensor(0.2672), tensor(0.2674), tensor(0.2692), tensor(0.2751), tensor(0.2762), tensor(0.2775), tensor(0.2788)]\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.7391), tensor(0.7378), tensor(0.7280), tensor(0.7275), tensor(0.7267), tensor(0.7129), tensor(0.7114), tensor(0.7091), tensor(0.7089), tensor(0.6973)]\n",
      "[tensor(0.2392), tensor(0.2480), tensor(0.2550), tensor(0.2574), tensor(0.2584), tensor(0.2591), tensor(0.2612), tensor(0.2616), tensor(0.2636), tensor(0.2639)]\n",
      "1\n",
      "[tensor(0.6390), tensor(0.6384), tensor(0.6372), tensor(0.6335), tensor(0.6334), tensor(0.6314), tensor(0.6301), tensor(0.6290), tensor(0.6265), tensor(0.6256)]\n",
      "[tensor(0.2605), tensor(0.2635), tensor(0.2638), tensor(0.2685), tensor(0.2712), tensor(0.2744), tensor(0.2753), tensor(0.2759), tensor(0.2765), tensor(0.2767)]\n",
      "2\n",
      "[tensor(0.6563), tensor(0.6556), tensor(0.6536), tensor(0.6522), tensor(0.6502), tensor(0.6462), tensor(0.6452), tensor(0.6448), tensor(0.6429), tensor(0.6418)]\n",
      "[tensor(0.2276), tensor(0.2514), tensor(0.2532), tensor(0.2533), tensor(0.2538), tensor(0.2564), tensor(0.2566), tensor(0.2566), tensor(0.2573), tensor(0.2583)]\n",
      "3\n",
      "[tensor(0.7488), tensor(0.7415), tensor(0.7356), tensor(0.7346), tensor(0.7223), tensor(0.7088), tensor(0.7027), tensor(0.7020), tensor(0.6999), tensor(0.6978)]\n",
      "[tensor(0.2458), tensor(0.2478), tensor(0.2482), tensor(0.2487), tensor(0.2515), tensor(0.2521), tensor(0.2576), tensor(0.2581), tensor(0.2602), tensor(0.2621)]\n",
      "4\n",
      "[tensor(0.6880), tensor(0.6874), tensor(0.6812), tensor(0.6741), tensor(0.6671), tensor(0.6667), tensor(0.6660), tensor(0.6658), tensor(0.6658), tensor(0.6636)]\n",
      "[tensor(0.2194), tensor(0.2445), tensor(0.2490), tensor(0.2491), tensor(0.2541), tensor(0.2548), tensor(0.2549), tensor(0.2553), tensor(0.2582), tensor(0.2586)]\n",
      "5\n",
      "[tensor(0.6851), tensor(0.6785), tensor(0.6742), tensor(0.6716), tensor(0.6711), tensor(0.6697), tensor(0.6658), tensor(0.6602), tensor(0.6554), tensor(0.6538)]\n",
      "[tensor(0.2357), tensor(0.2441), tensor(0.2517), tensor(0.2533), tensor(0.2568), tensor(0.2589), tensor(0.2591), tensor(0.2592), tensor(0.2598), tensor(0.2611)]\n",
      "6\n",
      "[tensor(0.7470), tensor(0.7391), tensor(0.7385), tensor(0.7325), tensor(0.7325), tensor(0.7273), tensor(0.7242), tensor(0.7233), tensor(0.7233), tensor(0.7215)]\n",
      "[tensor(0.2322), tensor(0.2462), tensor(0.2471), tensor(0.2480), tensor(0.2492), tensor(0.2509), tensor(0.2520), tensor(0.2530), tensor(0.2539), tensor(0.2558)]\n",
      "7\n",
      "[tensor(0.6739), tensor(0.6698), tensor(0.6635), tensor(0.6628), tensor(0.6625), tensor(0.6590), tensor(0.6552), tensor(0.6545), tensor(0.6518), tensor(0.6475)]\n",
      "[tensor(0.2245), tensor(0.2533), tensor(0.2534), tensor(0.2557), tensor(0.2586), tensor(0.2596), tensor(0.2601), tensor(0.2608), tensor(0.2615), tensor(0.2632)]\n",
      "8\n",
      "[tensor(0.7238), tensor(0.7117), tensor(0.7047), tensor(0.7017), tensor(0.7008), tensor(0.7005), tensor(0.6981), tensor(0.6977), tensor(0.6956), tensor(0.6952)]\n",
      "[tensor(0.2197), tensor(0.2218), tensor(0.2389), tensor(0.2418), tensor(0.2437), tensor(0.2453), tensor(0.2467), tensor(0.2472), tensor(0.2475), tensor(0.2515)]\n",
      "9\n",
      "[tensor(0.6877), tensor(0.6741), tensor(0.6736), tensor(0.6669), tensor(0.6621), tensor(0.6615), tensor(0.6593), tensor(0.6580), tensor(0.6566), tensor(0.6486)]\n",
      "[tensor(0.2236), tensor(0.2286), tensor(0.2302), tensor(0.2318), tensor(0.2334), tensor(0.2338), tensor(0.2362), tensor(0.2370), tensor(0.2370), tensor(0.2377)]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.7574), tensor(0.7408), tensor(0.7399), tensor(0.7373), tensor(0.7325), tensor(0.7267), tensor(0.7267), tensor(0.7254), tensor(0.7254), tensor(0.7253)]\n",
      "[tensor(0.2331), tensor(0.2460), tensor(0.2501), tensor(0.2527), tensor(0.2529), tensor(0.2562), tensor(0.2601), tensor(0.2601), tensor(0.2624), tensor(0.2625)]\n",
      "1\n",
      "[tensor(0.7054), tensor(0.7051), tensor(0.7049), tensor(0.7047), tensor(0.7043), tensor(0.7039), tensor(0.7018), tensor(0.6961), tensor(0.6954), tensor(0.6939)]\n",
      "[tensor(0.2139), tensor(0.2366), tensor(0.2380), tensor(0.2420), tensor(0.2429), tensor(0.2459), tensor(0.2501), tensor(0.2525), tensor(0.2534), tensor(0.2540)]\n",
      "2\n",
      "[tensor(0.7406), tensor(0.7325), tensor(0.7155), tensor(0.7151), tensor(0.7142), tensor(0.7133), tensor(0.7074), tensor(0.7032), tensor(0.7019), tensor(0.7003)]\n",
      "[tensor(0.2188), tensor(0.2308), tensor(0.2420), tensor(0.2474), tensor(0.2481), tensor(0.2498), tensor(0.2511), tensor(0.2517), tensor(0.2526), tensor(0.2537)]\n",
      "3\n",
      "[tensor(0.6954), tensor(0.6892), tensor(0.6891), tensor(0.6882), tensor(0.6875), tensor(0.6833), tensor(0.6784), tensor(0.6776), tensor(0.6765), tensor(0.6754)]\n",
      "[tensor(0.2362), tensor(0.2404), tensor(0.2437), tensor(0.2445), tensor(0.2487), tensor(0.2499), tensor(0.2501), tensor(0.2518), tensor(0.2577), tensor(0.2600)]\n",
      "4\n",
      "[tensor(0.7172), tensor(0.7116), tensor(0.7071), tensor(0.7050), tensor(0.7022), tensor(0.6940), tensor(0.6939), tensor(0.6914), tensor(0.6909), tensor(0.6869)]\n",
      "[tensor(0.2081), tensor(0.2308), tensor(0.2476), tensor(0.2489), tensor(0.2494), tensor(0.2511), tensor(0.2516), tensor(0.2524), tensor(0.2529), tensor(0.2535)]\n",
      "5\n",
      "[tensor(0.6525), tensor(0.6475), tensor(0.6410), tensor(0.6370), tensor(0.6360), tensor(0.6360), tensor(0.6359), tensor(0.6334), tensor(0.6324), tensor(0.6239)]\n",
      "[tensor(0.2386), tensor(0.2396), tensor(0.2408), tensor(0.2409), tensor(0.2409), tensor(0.2411), tensor(0.2417), tensor(0.2421), tensor(0.2434), tensor(0.2445)]\n",
      "6\n",
      "[tensor(0.7308), tensor(0.7232), tensor(0.7170), tensor(0.7115), tensor(0.7111), tensor(0.7104), tensor(0.7065), tensor(0.7062), tensor(0.7055), tensor(0.7054)]\n",
      "[tensor(0.2533), tensor(0.2544), tensor(0.2560), tensor(0.2569), tensor(0.2636), tensor(0.2646), tensor(0.2649), tensor(0.2652), tensor(0.2669), tensor(0.2669)]\n",
      "7\n",
      "[tensor(0.6751), tensor(0.6705), tensor(0.6555), tensor(0.6551), tensor(0.6504), tensor(0.6480), tensor(0.6463), tensor(0.6446), tensor(0.6441), tensor(0.6399)]\n",
      "[tensor(0.2306), tensor(0.2406), tensor(0.2476), tensor(0.2539), tensor(0.2555), tensor(0.2573), tensor(0.2605), tensor(0.2609), tensor(0.2615), tensor(0.2617)]\n",
      "8\n",
      "[tensor(0.7011), tensor(0.6982), tensor(0.6972), tensor(0.6966), tensor(0.6965), tensor(0.6940), tensor(0.6936), tensor(0.6935), tensor(0.6931), tensor(0.6908)]\n",
      "[tensor(0.2007), tensor(0.2333), tensor(0.2363), tensor(0.2417), tensor(0.2423), tensor(0.2444), tensor(0.2457), tensor(0.2469), tensor(0.2470), tensor(0.2480)]\n",
      "9\n",
      "[tensor(0.7203), tensor(0.7169), tensor(0.7077), tensor(0.7024), tensor(0.6999), tensor(0.6983), tensor(0.6935), tensor(0.6931), tensor(0.6909), tensor(0.6905)]\n",
      "[tensor(0.2349), tensor(0.2378), tensor(0.2409), tensor(0.2416), tensor(0.2451), tensor(0.2477), tensor(0.2514), tensor(0.2523), tensor(0.2531), tensor(0.2531)]\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 20/20 [00:19<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor(0.6443), tensor(0.6308), tensor(0.6070), tensor(0.6034), tensor(0.6000), tensor(0.5950), tensor(0.5949), tensor(0.5933), tensor(0.5926), tensor(0.5907)]\n",
      "[tensor(0.2155), tensor(0.2164), tensor(0.2210), tensor(0.2279), tensor(0.2329), tensor(0.2426), tensor(0.2431), tensor(0.2435), tensor(0.2451), tensor(0.2452)]\n",
      "1\n",
      "[tensor(0.7014), tensor(0.6978), tensor(0.6957), tensor(0.6922), tensor(0.6902), tensor(0.6889), tensor(0.6878), tensor(0.6868), tensor(0.6867), tensor(0.6866)]\n",
      "[tensor(0.2215), tensor(0.2259), tensor(0.2302), tensor(0.2380), tensor(0.2438), tensor(0.2546), tensor(0.2556), tensor(0.2558), tensor(0.2558), tensor(0.2566)]\n",
      "2\n",
      "[tensor(0.7546), tensor(0.7384), tensor(0.7281), tensor(0.7272), tensor(0.7260), tensor(0.7244), tensor(0.7238), tensor(0.7229), tensor(0.7203), tensor(0.7197)]\n",
      "[tensor(0.1957), tensor(0.2041), tensor(0.2072), tensor(0.2130), tensor(0.2273), tensor(0.2331), tensor(0.2332), tensor(0.2370), tensor(0.2382), tensor(0.2407)]\n",
      "3\n",
      "[tensor(0.8027), tensor(0.7988), tensor(0.7963), tensor(0.7941), tensor(0.7863), tensor(0.7856), tensor(0.7850), tensor(0.7777), tensor(0.7714), tensor(0.7712)]\n",
      "[tensor(0.2129), tensor(0.2153), tensor(0.2423), tensor(0.2516), tensor(0.2546), tensor(0.2557), tensor(0.2572), tensor(0.2580), tensor(0.2600), tensor(0.2621)]\n",
      "4\n",
      "[tensor(0.6970), tensor(0.6435), tensor(0.6408), tensor(0.6401), tensor(0.6378), tensor(0.6334), tensor(0.6324), tensor(0.6275), tensor(0.6273), tensor(0.6261)]\n",
      "[tensor(0.2364), tensor(0.2540), tensor(0.2602), tensor(0.2606), tensor(0.2667), tensor(0.2688), tensor(0.2695), tensor(0.2698), tensor(0.2705), tensor(0.2713)]\n",
      "5\n",
      "[tensor(0.7328), tensor(0.7280), tensor(0.7261), tensor(0.7226), tensor(0.7209), tensor(0.7204), tensor(0.7202), tensor(0.7167), tensor(0.7161), tensor(0.7136)]\n",
      "[tensor(0.2271), tensor(0.2531), tensor(0.2541), tensor(0.2552), tensor(0.2553), tensor(0.2578), tensor(0.2579), tensor(0.2593), tensor(0.2628), tensor(0.2628)]\n",
      "6\n",
      "[tensor(0.7005), tensor(0.6929), tensor(0.6918), tensor(0.6872), tensor(0.6870), tensor(0.6851), tensor(0.6849), tensor(0.6841), tensor(0.6822), tensor(0.6808)]\n",
      "[tensor(0.2294), tensor(0.2370), tensor(0.2379), tensor(0.2387), tensor(0.2435), tensor(0.2508), tensor(0.2553), tensor(0.2553), tensor(0.2561), tensor(0.2583)]\n",
      "7\n",
      "[tensor(0.7634), tensor(0.7598), tensor(0.7553), tensor(0.7552), tensor(0.7504), tensor(0.7497), tensor(0.7493), tensor(0.7492), tensor(0.7490), tensor(0.7482)]\n",
      "[tensor(0.2228), tensor(0.2259), tensor(0.2263), tensor(0.2269), tensor(0.2280), tensor(0.2314), tensor(0.2325), tensor(0.2344), tensor(0.2352), tensor(0.2355)]\n",
      "8\n",
      "[tensor(0.6291), tensor(0.6243), tensor(0.6218), tensor(0.6189), tensor(0.6185), tensor(0.6168), tensor(0.6158), tensor(0.6130), tensor(0.6124), tensor(0.6123)]\n",
      "[tensor(0.2120), tensor(0.2283), tensor(0.2560), tensor(0.2578), tensor(0.2606), tensor(0.2624), tensor(0.2631), tensor(0.2640), tensor(0.2643), tensor(0.2662)]\n",
      "9\n",
      "[tensor(0.6839), tensor(0.6716), tensor(0.6685), tensor(0.6666), tensor(0.6650), tensor(0.6644), tensor(0.6642), tensor(0.6639), tensor(0.6624), tensor(0.6624)]\n",
      "[tensor(0.2025), tensor(0.2192), tensor(0.2208), tensor(0.2376), tensor(0.2446), tensor(0.2473), tensor(0.2475), tensor(0.2509), tensor(0.2529), tensor(0.2539)]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import heapq\n",
    "client_pos_datasets, client_neg_datasets = [], []\n",
    "for i, sampled_data in enumerate(local_datasets):\n",
    "    print(i)\n",
    "    sampled_embeddings = model.encode(sampled_data[\"instruction\"])\n",
    "    # 假设 embeddings 是你的嵌入数据\n",
    "    k = 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(sampled_embeddings)\n",
    "    concated_embeddings = model.encode(public_datasets[i][\"instruction\"])\n",
    "    clusters = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32)\n",
    "    concated_embeddings = torch.tensor(concated_embeddings, dtype=torch.float32)\n",
    "    similarity_scores = clusters @ concated_embeddings.T\n",
    "    top_idxs = []\n",
    "    bot_idxs = []\n",
    "    for i in range(similarity_scores.shape[0]):\n",
    "        print(i)\n",
    "        tmp = similarity_scores[i]\n",
    "        # print(similarity_scores[i][:10])\n",
    "        top_idxs.append(heapq.nlargest(500, range(len(tmp)-1), key=lambda x: tmp[x]))\n",
    "        bot_idxs.append(heapq.nsmallest(500, range(len(tmp)-1), key=lambda x: tmp[x]))\n",
    "        top_scores = [similarity_scores[i][idx] for idx in top_idxs[i][:10]]\n",
    "        bot_scores = [similarity_scores[i][idx] for idx in bot_idxs[i][:10]]\n",
    "        print(top_scores)\n",
    "        print(bot_scores)\n",
    "        \n",
    "    pos_datasets: Dataset = []\n",
    "    neg_datasets: Dataset = []\n",
    "    # for i in range(len(top_idxs)):\n",
    "    #     instruction_length = len(public_datasets[i][\"instruction\"])\n",
    "    #     filtered_top_idxs = list(filter(lambda idx: idx < instruction_length, top_idxs[i]))\n",
    "    #     filtered_bot_idxs = list(filter(lambda idx: idx < instruction_length, bot_idxs[i]))\n",
    "        # pos_datasets.append(public_datasets[i].select(filtered_top_idxs))\n",
    "        # neg_datasets.append(public_datasets[i].select(filtered_bot_idxs))\n",
    "    top_idxs=np.concatenate(top_idxs,axis=None)\n",
    "    bot_idxs=np.concatenate(bot_idxs,axis=None)\n",
    "    pos_datasets = public_datasets[i].select(top_idxs)\n",
    "    neg_datasets = public_datasets[i].select(bot_idxs)\n",
    "    pos_datasets = concatenate_datasets([pos_datasets, sampled_data])\n",
    "    neg_datasets = concatenate_datasets([neg_datasets, sampled_data])\n",
    "    # pos_datasets = pos_datasets.shuffle(seed=42)\n",
    "    # neg_datasets = neg_datasets.shuffle(seed=42)\n",
    "    client_pos_datasets.append(pos_datasets)\n",
    "    client_neg_datasets.append(neg_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098fc0ec8a9c402d9d377cbfe8f1c888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a3d86d1b4c480ea5642f7d2bf9a260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5206ce1d70854b30836efb3355000c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60870b0511d43b8a3329a1158e44da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc4f5af9da7406c93013d567f61ebdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9164c5500f4c5a87c823662e9ff072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c104e2e8a0c40dfa47ccd9ea58e2f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d3f9bb63ca47b7ad2d1aee6d02262b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c6d66348d240bf8ddf5ee413b03061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7b82d4a9094941b8da7cef76390868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# client_pos_datasets, client_neg_datasets = client_pos_datasets[-10:], client_neg_datasets[-10:]\n",
    "for i, pos_data in enumerate(client_pos_datasets):\n",
    "    pos_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/pos_{i}.parquet\")\n",
    "# for i, (pos_data, neg_data) in enumerate(zip(client_pos_datasets, client_neg_datasets)):\n",
    "#     pos_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/pos_{i}.parquet\")\n",
    "#     neg_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/neg_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造pos+diversity 数据集，一半 pos，一半 diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "client_pos_datasets=[]\n",
    "for i, sampled_data in enumerate(local_datasets):\n",
    "    print(i)\n",
    "    sampled_embeddings = model.encode(sampled_data[\"instruction\"])\n",
    "    # 假设 embeddings 是你的嵌入数据\n",
    "    k = 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(sampled_embeddings)\n",
    "    print(kmeans)\n",
    "    concated_embeddings = model.encode(public_datasets[i][\"instruction\"])\n",
    "    clusters = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32)\n",
    "    concated_embeddings = torch.tensor(concated_embeddings, dtype=torch.float32)\n",
    "    similarity_scores = clusters @ concated_embeddings.T\n",
    "    top_idxs = []\n",
    "    for i in range(similarity_scores.shape[0]):\n",
    "        tmp = similarity_scores[i]\n",
    "        top_idxs.append(heapq.nlargest(250, range(len(tmp)), key=tmp.__getitem__))\n",
    "    pos_datasets: Dataset = []\n",
    "    # top_idxs去重，其余作为 diversity\n",
    "    top_idxs = set(np.concatenate(top_idxs,axis=0))\n",
    "    try: top_idxs.remove(len(public_datasets[i]))\n",
    "    except: pass\n",
    "    pos_datasets = public_datasets[i].select(top_idxs)\n",
    "    print(len(top_idxs))\n",
    "    # 从public_datasets[i]中去掉 top_idxs\n",
    "    all_idxs = set(range(len(public_datasets[i])))\n",
    "    remain_idxs = list(all_idxs-top_idxs)\n",
    "    random_idxs = random.sample(remain_idxs, 5000-len(top_idxs))\n",
    "    diversity_datasets = public_datasets[i].select(random_idxs)\n",
    "    pos_datasets = concatenate_datasets([pos_datasets, diversity_datasets, sampled_data])\n",
    "    pos_datasets = pos_datasets.shuffle(seed=42)\n",
    "    client_pos_datasets.append(pos_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pos_data in enumerate(client_pos_datasets):\n",
    "    pos_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/T_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造去重 pos 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedSet([3, 7, 1])\n"
     ]
    }
   ],
   "source": [
    "from ordered_set import OrderedSet\n",
    "tmp = OrderedSet([4,5,3,7,1])\n",
    "tmp1 = OrderedSet([4,5])\n",
    "for t in tmp1: tmp.discard(t)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "client_pos_datasets=[]\n",
    "for i, sampled_data in enumerate(local_datasets):\n",
    "    print(i)\n",
    "    sampled_embeddings = model.encode(sampled_data[\"instruction\"])\n",
    "    # 假设 embeddings 是你的嵌入数据\n",
    "    k = 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(sampled_embeddings)\n",
    "    print(kmeans)\n",
    "    concated_embeddings = model.encode(public_datasets[i][\"instruction\"])\n",
    "    clusters = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32)\n",
    "    concated_embeddings = torch.tensor(concated_embeddings, dtype=torch.float32)\n",
    "    top_idxs:OrderedSet = OrderedSet()\n",
    "    remain_idxs = OrderedSet(range(len(public_datasets[i])))\n",
    "    for i in range(k):\n",
    "        similarity_scores = clusters[i] @ concated_embeddings.T\n",
    "        top_idx = list(OrderedSet(heapq.nlargest(5000, range(len(similarity_scores)), key=similarity_scores.__getitem__))-top_idxs)[:500]\n",
    "        top_idxs.update(top_idx)\n",
    "        print(\"top_idxs\", len(top_idxs))\n",
    "        remain_idxs.difference_update(top_idx)\n",
    "        print(\"remain_idxs\", len(remain_idxs))\n",
    "\n",
    "    try: top_idxs.remove(len(public_datasets[i]))\n",
    "    except: pass\n",
    "    pos_datasets = public_datasets[i].select(list(top_idxs))\n",
    "    pos_datasets = concatenate_datasets([pos_datasets, sampled_data])\n",
    "    pos_datasets = pos_datasets.shuffle(seed=42)\n",
    "    client_pos_datasets.append(pos_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb224ded27c64c5faf2f7a6b08879e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2457c2f4ab94e118ccc91dbc46dccda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2009501373746e0a7609ce5c60566b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be281007d7e40adb369a937fa95e110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc479e5ad189452cbd4536607f718671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2a59f72e974c31a1047cbb14660ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e56bc1bb2b4298b4d110ba929b38b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5099 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec9454cb39943848adae31ba6964224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7400973a4f64f4c9f69da49650ace34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c1e798641b4e6183267790fae8815d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, pos_data in enumerate(client_pos_datasets):\n",
    "    pos_data.save_to_disk(f\"/mnt/bn/data-tns-live-llm/leon/datasets/fed_data/pos_nodup_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
