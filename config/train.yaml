model_name_or_path: "mistralai/Mistral-7B-Instruct-v0.2"
dataset_name: "vicgalle/alpaca-gpt4"
dataset_sample: 20000
fed_alg: "fedavg"
num_clients: 20
sample_clients: 10
max_steps: 10
num_rounds: 10
batch_size: 16
gradient_accumulation_steps: 1
seq_length: 512
peft_lora_r: 32
peft_lora_alpha: 64
use_peft: true
load_in_4bit: true
output_dir: "./output"
template: "alpaca"
save_model_freq: 1
